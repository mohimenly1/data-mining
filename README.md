# دراسة استخراج الأنماط وتأثير التجميع على الأداء الأكاديمي

## الخطوات الأكاديمية والمنهجية

### 1. الهدف من الدراسة
- فهم العلاقات الكامنة بين خصائص الطلاب (العمر، المدينة، النظام الدراسي، التخصص، إلخ) وأدائهم الأكاديمي (نجاح أو رسوب).
- تقييم أثر التجميع (K-Means) على جودة القواعد المستخرجة بخوارزمية Apriori، مع مقارنة النتائج قبل التجميع وبعده.

### 2. مصادر البيانات وتعريف المتغيرات
- المصدر: ملف `high_school.csv` يحتوي على 114,240 سجلًا.
- أبرز الحقول: `date of birth`, `city`, `Gender`, `Secondary system`, `School system`, `Year of registration`, `Pass or fail?`, `Specialization ID`, `High school success rate`.
- المخرجات الوسيطة والنهائية محفوظة في مجلد `outputs/`، وتشمل جداول القواعد، ملخص العناقيد، الرسوم التفاعلية، والملفات النصية التوثيقية.

### 3. المعالجة المسبقة (Data Pre-processing)
- إزالة التكرارات لتجنب تضخيم وزن الطلاب المكررين.
- توحيد أسماء الأعمدة والقيم وإزالة الفراغات.
- معالجة القيم المفقودة، خاصة السنة الأكاديمية (`Academic year`) بإسناد القيمة `Unknown`.
- التأكد من أن الأعمدة الرقمية (`date of birth`, `Year of registration`, `High school success rate`) في هيئة رقمية.
- إنشاء خصائص مشتقة:
  - `birth_bucket`: فئات زمنية لسنة الميلاد (`<=1989`, `1990-1992`, `1993-1995`, `>=1996`).
  - `registration_bucket`: فئات زمنية لسنة التسجيل (`<=2010`, `2011-2012`, `2013-2014`, `>=2015`).
  - `success_rate_band`: شرائح لنسبة النجاح (`<70`, `70-79`, `80-89`, `90-100`).
- النتائج المفصلة للمعالجة موثقة في `outputs/documentation.txt`.

### 4. تحويل البيانات لإعداد معاملات Apriori
- استخدام One-Hot Encoding لتحويل كل قيمة إلى عنصر (Item) على شكل `Feature=Value`.
- حفظ مصفوفة المعاملات في الذاكرة وتشغيل Apriori من خلال `mlxtend.frequent_patterns`.
- الكود المسئول عن ذلك موجود في سكربت `analysis_pipeline.py`.

### 5. تحليل أولي للبيانات
- قياس النسبة الكلية للنجاح (~80%) وتوزيع حالات النجاح والرسوب.
- التعرف على المدن الأكثر تمثيلًا ومعدلات النجاح فيها لتحديد النقاط الساخنة.

![توزيع النجاح والرسوب](./outputs/pass_fail_distribution.png)
![معدلات النجاح حسب المدينة](./outputs/city_success_rates.png)

### 6. استخراج قواعد الارتباط قبل التجميع
- إعدادات Apriori قبل التجميع:
  - الحد الأدنى للدعم (Support) = 0.05.
  - الحد الأدنى للثقة (Confidence) = 0.6.
  - أقصى عدد للقواعد المعروضة = 30.
- النتائج محفوظة في `outputs/apriori_rules_before.csv`.
- أبرز قاعدة: الطلاب ذوو نسب نجاح أقل من 70% والمسجلون بعد 2015 غالبًا يرتبطون بالفشل والنظام الدراسي النظامي (`regular`).
- ملخص النتائج السريعة موجود في `outputs/summary.txt`.

### 7. تطبيق التجميع باستخدام K-Means
- تجهيز مصفوفة السمات العددية والرمزية، ثم تطبيق StandardScaler.
- اختبار قيم `k` (عدد العناقيد) من 2 إلى 8 باستخدام مؤشر Silhouette.
- اختيار `k=6` كأفضل قيمة، والنتائج محفوظة في `outputs/kmeans_silhouette_scores.json`.
- ملخص العناقيد (عدد الطلاب، معدل النجاح الداخلي، متوسط نسب الثانوية) موجود في `outputs/cluster_summary.csv`.

![تقييم قيم k](./outputs/silhouette_scores.png)
![ملخص العناقيد](./outputs/cluster_summary.png)

### 8. إعادة تطبيق Apriori داخل العناقيد
- لكل عنقود يتم تطبيق Apriori بحد دعم ديناميكي `max(0.02, 50/عدد السجلات)` وثقة 0.6.
- الهدف: اكتشاف قواعد أكثر دقة تعكس خصائص كل مجموعة.
- النتائج الفردية تُدمج في `outputs/apriori_rules_after_clusters.csv` (إجمالي 100 قاعدة بعد التجميع).
- الرسوم المرافقة:
  - مقارنة عدد القواعد قبل/بعد التجميع (`rules_comparison.png`).
  - أفضل القواعد بعد التجميع مرتبة حسب قيمة الرفع (`top_rules_after.png`).

![مقارنة القواعد قبل وبعد](./outputs/rules_comparison.png)
![أهم القواعد بعد التجميع](./outputs/top_rules_after.png)

### 9. التفسير والتوصيات الأكاديمية
- العناقيد ذات الأداء المنخفض (مثل العنقود 1) تحتاج تدخلًا عاجلًا؛ تم تحديد المدن الغالبة لتوجيه البرامج التصحيحية.
- العناقيد المتميزة (مثل 2 و3) تصل نسبة النجاح فيها إلى 100% ويمكن الاستفادة من ممارساتها الناجحة (التخصصات السائدة: تحليل بيانات، محاسبة).
- الطلاب المسجلون في الأعوام الحديثة (>=2015) لديهم أعلى معدلات الرسوب؛ يوصى بتقوية برامج الدعم لهم.
- التوصيات مفصلة في `outputs/documentation.md` و`outputs/documentation.txt`.

### 10. الخلاصة والاستنتاج العلمي
- منهجية الجمع بين K-Means وApriori حسّنت من دقة الأنماط مقارنة بالتطبيق المباشر لـ Apriori على كامل البيانات:
  - قبل التجميع: 30 قاعدة عامة مع ضوضاء عالية.
  - بعد التجميع: 100 قاعدة دقيقة وموجهة لكل عنقود.
- تؤكد النتائج أن تقليل الضوضاء عبر التجميع يساهم في قرارات مبنية على بيانات أكثر موثوقية.
- التخطيط الدوري لتحديث البيانات وإعادة تشغيل التحليل سيضمن مراقبة مستمرة لاتجاهات الأداء الأكاديمي.

### 11. كيفية إعادة التشغيل ومحتويات المجلد
- لتنفيذ الدراسة من جديد:

```bash
python analysis_pipeline.py
```

- أهم الملفات المرجعية:
  - `analysis_pipeline.py`: الكود البرمجي الكامل لكافة الخطوات.
  - `outputs/apriori_rules_before.csv`: قواعد الارتباط قبل تطبيق K-Means.
  - `outputs/apriori_rules_after_clusters.csv`: القواعد بعد التجميع.
  - `outputs/cluster_summary.csv`: خصائص كل عنقود.
  - `outputs/summary.txt`: ملخص رقمي سريع.
  - `outputs/documentation.txt`: سرد تفصيلي للخطوات والنتائج.
  - `outputs/documentation.md`: ملف العرض النهائي بالصور والشرح.

