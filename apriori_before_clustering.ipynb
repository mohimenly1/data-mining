{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Importing libraries...\n",
      "âœ… Libraries imported successfully.\n",
      "ðŸ’¡ Make sure you have mlxtend installed (`pip install mlxtend`)\n",
      "\n",
      "STEP 2: Loading and cleaning data...\n",
      "âœ… Data loaded and cleaned. Working with 59615 records.\n",
      "\n",
      "STEP 3: Preparing data for Apriori algorithm...\n",
      "âœ… Data has been one-hot encoded and is ready.\n",
      "Sample of encoded data:\n",
      "   city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©  city_Ø§Ù„Ø¨Ø±ÙŠÙ‚Ø©  city_Ø§Ù„Ø¬Ù…ÙŠÙ„  city_Ø§Ù„Ø­Ø±Ø§Ø¨Ø©  city_Ø§Ù„Ø­ÙˆØ§Ù…Ù€Ù€Ù€Ù€Ù€Ø¯  \\\n",
      "0          False         False        False         False              False   \n",
      "1          False         False        False         False              False   \n",
      "2          False         False        False         False              False   \n",
      "3          False         False        False         False              False   \n",
      "4          False         False        False         False              False   \n",
      "\n",
      "   city_Ø§Ù„Ø±ÙŠØ§ÙŠÙ†Ø©  city_Ø§Ù„Ø²Ø§ÙˆÙŠØ©  city_Ø§Ù„Ø²Ù†ØªØ§Ù†  city_Ø§Ù„Ø²ÙˆÙŠØ©  city_Ø§Ù„Ø´Ù‚ÙŠÙ‚Ø©  ...  \\\n",
      "0          False         False         False        False         False  ...   \n",
      "1          False         False         False        False         False  ...   \n",
      "2          False         False         False        False         False  ...   \n",
      "3          False         False         False        False         False  ...   \n",
      "4          False         False         False        False         False  ...   \n",
      "\n",
      "   Specialization ID_Economy  Specialization ID_Finance and banking  \\\n",
      "0                      False                                  False   \n",
      "1                      False                                  False   \n",
      "2                      False                                  False   \n",
      "3                      False                                  False   \n",
      "4                      False                                  False   \n",
      "\n",
      "   Specialization ID_General  Specialization ID_Management  \\\n",
      "0                      False                         False   \n",
      "1                      False                         False   \n",
      "2                      False                         False   \n",
      "3                      False                         False   \n",
      "4                      False                         False   \n",
      "\n",
      "   Specialization ID_business management  Pass or fail?_Failed  \\\n",
      "0                                  False                  True   \n",
      "1                                  False                  True   \n",
      "2                                  False                  True   \n",
      "3                                  False                  True   \n",
      "4                                  False                  True   \n",
      "\n",
      "   Pass or fail?_successful  rate_category_Rate_Low  \\\n",
      "0                     False                   False   \n",
      "1                     False                   False   \n",
      "2                     False                   False   \n",
      "3                     False                   False   \n",
      "4                     False                   False   \n",
      "\n",
      "   rate_category_Rate_Medium  rate_category_Rate_High  \n",
      "0                      False                     True  \n",
      "1                       True                    False  \n",
      "2                      False                     True  \n",
      "3                      False                     True  \n",
      "4                      False                     True  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "STEP 4: Applying Apriori algorithm...\n",
      "âœ… Found 287 frequent itemsets.\n",
      "âœ… Generated 1150 association rules.\n",
      "\n",
      "STEP 5: Top 15 Association Rules Found in the Full Dataset:\n",
      "                                           antecedents  \\\n",
      "585           (Gender_Fmale, Pass or fail?_successful)   \n",
      "580              (rate_category_Rate_High, city_ØºØ±ÙŠØ§Ù†)   \n",
      "587                          (rate_category_Rate_High)   \n",
      "578  (Pass or fail?_successful, Gender_Fmale, city_...   \n",
      "115                                    (city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©)   \n",
      "114    (rate_category_Rate_Low, School system_regular)   \n",
      "545              (Gender_Fmale, School system_regular)   \n",
      "540              (rate_category_Rate_High, city_ØºØ±ÙŠØ§Ù†)   \n",
      "822  (School system_regular, Gender_Fmale, Pass or ...   \n",
      "831                          (rate_category_Rate_High)   \n",
      "116                           (rate_category_Rate_Low)   \n",
      "113             (city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©, School system_regular)   \n",
      "893  (Pass or fail?_Failed, Gender_Male, School sys...   \n",
      "904                           (rate_category_Rate_Low)   \n",
      "6                                      (city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©)   \n",
      "\n",
      "                                           consequents  antecedent support  \\\n",
      "585              (rate_category_Rate_High, city_ØºØ±ÙŠØ§Ù†)            0.234270   \n",
      "580           (Gender_Fmale, Pass or fail?_successful)            0.139696   \n",
      "587  (Pass or fail?_successful, Gender_Fmale, city_...            0.206475   \n",
      "578                          (rate_category_Rate_High)            0.166971   \n",
      "115    (rate_category_Rate_Low, School system_regular)            0.181062   \n",
      "114                                    (city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©)            0.203036   \n",
      "545              (rate_category_Rate_High, city_ØºØ±ÙŠØ§Ù†)            0.330756   \n",
      "540              (Gender_Fmale, School system_regular)            0.139696   \n",
      "822                          (rate_category_Rate_High)            0.223484   \n",
      "831  (School system_regular, Gender_Fmale, Pass or ...            0.206475   \n",
      "116             (city_Ø§Ù„Ø£ØµØ§Ø¨Ø¹Ø©, School system_regular)            0.209863   \n",
      "113                           (rate_category_Rate_Low)            0.180257   \n",
      "893                           (rate_category_Rate_Low)            0.203992   \n",
      "904  (Pass or fail?_Failed, Gender_Male, School sys...            0.209863   \n",
      "6                             (rate_category_Rate_Low)            0.181062   \n",
      "\n",
      "     consequent support   support  confidence      lift  representativity  \\\n",
      "585            0.139696  0.050239    0.214449  1.535110               1.0   \n",
      "580            0.234270  0.050239    0.359630  1.535110               1.0   \n",
      "587            0.166971  0.050239    0.243318  1.457243               1.0   \n",
      "578            0.206475  0.050239    0.300884  1.457243               1.0   \n",
      "115            0.203036  0.053443    0.295164  1.453751               1.0   \n",
      "114            0.181062  0.053443    0.263219  1.453751               1.0   \n",
      "545            0.139696  0.065453    0.197890  1.416574               1.0   \n",
      "540            0.330756  0.065453    0.468540  1.416574               1.0   \n",
      "822            0.206475  0.065336    0.292352  1.415918               1.0   \n",
      "831            0.223484  0.065336    0.316435  1.415918               1.0   \n",
      "116            0.180257  0.053443    0.254656  1.412741               1.0   \n",
      "113            0.209863  0.053443    0.296482  1.412741               1.0   \n",
      "893            0.209863  0.060237    0.295288  1.407050               1.0   \n",
      "904            0.203992  0.060237    0.287027  1.407050               1.0   \n",
      "6              0.209863  0.053443    0.295164  1.406458               1.0   \n",
      "\n",
      "     leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "585  0.017512    1.095160       0.455227  0.155189   0.086891    0.287040  \n",
      "580  0.017512    1.195762       0.405184  0.155189   0.163713    0.287040  \n",
      "587  0.015764    1.100896       0.395416  0.155439   0.091649    0.272101  \n",
      "578  0.015764    1.135041       0.376665  0.155439   0.118974    0.272101  \n",
      "115  0.016681    1.130708       0.381133  0.161627   0.115599    0.279191  \n",
      "114  0.016681    1.111508       0.391642  0.161627   0.100321    0.279191  \n",
      "545  0.019248    1.072551       0.439408  0.161614   0.067643    0.333215  \n",
      "540  0.019248    1.259256       0.341823  0.161614   0.205880    0.333215  \n",
      "822  0.019192    1.121355       0.378285  0.179188   0.108222    0.304393  \n",
      "831  0.019192    1.135980       0.370177  0.179188   0.119703    0.304393  \n",
      "116  0.015614    1.099819       0.369754  0.158736   0.090759    0.275569  \n",
      "113  0.015614    1.123123       0.356399  0.158736   0.109625    0.275569  \n",
      "893  0.017426    1.121220       0.363430  0.170343   0.108114    0.291158  \n",
      "904  0.017426    1.116463       0.366131  0.170343   0.104314    0.291158  \n",
      "6    0.015445    1.121022       0.352889  0.158358   0.107957    0.274910  \n",
      "\n",
      "--- How to Read the Table ---\n",
      "- antecedents: The 'IF' part of the rule. (e.g., IF student is from Gharyan)\n",
      "- consequents: The 'THEN' part of the rule. (e.g., THEN they are likely to pass)\n",
      "- support: How frequent the items in the rule are in the whole dataset.\n",
      "- confidence: The probability of seeing the 'consequents' when the 'antecedents' are present.\n",
      "- lift: How much more likely the 'consequents' are, given the 'antecedents'. A lift of 1.5 means 50% more likely.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#                      Phase 2.1: Association Rules (Apriori) - BEFORE Clustering\n",
    "# ==============================================================================\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 1: Import Libraries\n",
    "# -----------------------------------------------------\n",
    "print(\"STEP 1: Importing libraries...\")\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# The libraries for Apriori algorithm\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"âœ… Libraries imported successfully.\")\n",
    "print(\"ðŸ’¡ Make sure you have mlxtend installed (`pip install mlxtend`)\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 2: Load and Clean Data\n",
    "# -----------------------------------------------------\n",
    "print(\"\\nSTEP 2: Loading and cleaning data...\")\n",
    "file_name = \"high_school.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_name)\n",
    "    df_cleaned = df.dropna()\n",
    "    print(f\"âœ… Data loaded and cleaned. Working with {len(df_cleaned)} records.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ERROR: The file '{file_name}' was not found.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 3: Prepare Data for Apriori\n",
    "# -----------------------------------------------------\n",
    "print(\"\\nSTEP 3: Preparing data for Apriori algorithm...\")\n",
    "\n",
    "# Apriori works with categorical data. We will select relevant columns.\n",
    "# We will also convert the numerical 'High school success rate' into categories.\n",
    "\n",
    "# Binning the success rate into categories: Low, Medium, High\n",
    "df_cleaned['rate_category'] = pd.cut(df_cleaned['High school success rate'],\n",
    "                                     bins=[0, 70, 85, 101],\n",
    "                                     labels=['Rate_Low', 'Rate_Medium', 'Rate_High'],\n",
    "                                     right=False)\n",
    "\n",
    "# Select the columns we want to find rules between\n",
    "df_rules = df_cleaned[['city', 'Gender', 'School system', 'Specialization ID', 'Pass or fail?', 'rate_category']]\n",
    "\n",
    "# Apriori requires data in a one-hot encoded format (True/False or 1/0 for each value)\n",
    "df_encoded = pd.get_dummies(df_rules)\n",
    "print(\"âœ… Data has been one-hot encoded and is ready.\")\n",
    "print(\"Sample of encoded data:\")\n",
    "print(df_encoded.head())\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 4: Apply Apriori and Generate Rules\n",
    "# -----------------------------------------------------\n",
    "print(\"\\nSTEP 4: Applying Apriori algorithm...\")\n",
    "\n",
    "# Find frequent itemsets with a minimum support of 5%\n",
    "# `min_support` is a critical parameter. You may need to adjust it.\n",
    "# A lower support finds more (but possibly less important) rules.\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.05, use_colnames=True)\n",
    "print(f\"âœ… Found {len(frequent_itemsets)} frequent itemsets.\")\n",
    "\n",
    "# Generate association rules from the frequent itemsets\n",
    "# We are looking for rules with high \"lift\" and \"confidence\"\n",
    "# `lift` > 1 indicates a positive correlation.\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "print(f\"âœ… Generated {len(rules)} association rules.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 5: Display and Interpret the Results\n",
    "# -----------------------------------------------------\n",
    "print(\"\\nSTEP 5: Top 15 Association Rules Found in the Full Dataset:\")\n",
    "\n",
    "# Sort the rules by 'lift' to see the strongest relationships\n",
    "rules_sorted = rules.sort_values(by='lift', ascending=False)\n",
    "\n",
    "# Display the top rules\n",
    "print(rules_sorted.head(15))\n",
    "\n",
    "print(\"\\n--- How to Read the Table ---\")\n",
    "print(\"- antecedents: The 'IF' part of the rule. (e.g., IF student is from Gharyan)\")\n",
    "print(\"- consequents: The 'THEN' part of the rule. (e.g., THEN they are likely to pass)\")\n",
    "print(\"- support: How frequent the items in the rule are in the whole dataset.\")\n",
    "print(\"- confidence: The probability of seeing the 'consequents' when the 'antecedents' are present.\")\n",
    "print(\"- lift: How much more likely the 'consequents' are, given the 'antecedents'. A lift of 1.5 means 50% more likely.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
